{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_files_path = r'random_songs_split_after_crawling'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern of date and views as taken from youtube:\n",
    "pattern = re.compile(\"^([A-Z][a-z]{1}[A-z])[ ](0?[1-9]|[12][0-9]|3[01])[ ]\\d{4}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concats youtube and google trends crawling data from many small CSVs.\n",
    "def union_csvs(path):\n",
    "    results_df = pd.DataFrame()\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".csv\") and not filename.startswith('combinedfile'):\n",
    "            file_df = pd.read_csv(path+'\\\\' +filename)\n",
    "            results_df = results_df.append(file_df)\n",
    "    return results_df.drop_duplicates(subset='track_id')\n",
    "\n",
    "# normalizes \n",
    "def normalize(df):\n",
    "#     df['duration_ms_stand'] = np.where(df['duration_ms'] >= 10 * 60 * 1000, 10 * 60 * 1000, df['duration_ms'])\n",
    "    df = df[df['duration_ms'] <= 10 * 60 * 1000]\n",
    "    df['duration_norm'] = (df['duration_ms']-df['duration_ms'].min())/(df['duration_ms'].max()-df['duration_ms'].min())\n",
    "    \n",
    "    df['loudness_stand'] = np.where(df['loudness'] <= -40, -40 , df['loudness'])\n",
    "    df['loudness_norm'] = (df['loudness_stand']-df['loudness_stand'].min())/(df['loudness_stand'].max()-df['loudness_stand'].min())\n",
    "\n",
    "    df['tempo_norm'] = (df['tempo']-df['tempo'].min())/(df['tempo'].max()-df['tempo'].min())\n",
    "    return df\n",
    "    \n",
    "# calculates the number of days passed since the clip was uploaded to youtube\n",
    "def days(strdate):\n",
    "    strdate = strdate.lstrip()\n",
    "    date = datetime.strptime(strdate, '%b %d %Y')\n",
    "    date_oct = datetime.strptime('Oct 1 2018', '%b %d %Y')\n",
    "\n",
    "    if date_oct <= date:\n",
    "        return -1\n",
    "\n",
    "    return (date.today() - date).days\n",
    "\n",
    "# extracts the number of views and number of days since file was uploaded\n",
    "def extract_dates_and_views(data):\n",
    "    print(str(len(data)) + ' before filtering') \n",
    "\n",
    "    data = data[data['date_and_views'] != \"(None, None)\"]\n",
    "    print(str(len(data)) + ' after removing rows when views and dates are both None') \n",
    "    data['str_dv'] = data['date_and_views'].astype(str)\n",
    "    data['str_dv'] = data.str_dv.apply(lambda x: x.replace('(','').replace(')','',).replace(',','-',1).split('-'))\n",
    "    data['views'] = data.str_dv.apply(lambda x: x[0].replace(\"'\", ''))\n",
    "    data = data[data['views'].apply(lambda x: x.isdigit())]\n",
    "    print(str(len(data)) + ' after removing rows when views is not a digit') \n",
    "    data['views'] = data.views.apply(lambda x: int(x))\n",
    "    data['upload_date'] = data.str_dv.apply(lambda x: x[1].replace(',','').replace('on','').replace(\"'\",'').lstrip())\n",
    "    data = data[data['upload_date'] != \"None\"]\n",
    "    print(str(len(data)) + ' after removing rows where date is None') \n",
    "    data = data[data.upload_date.apply(lambda s: pattern.match(s) != None)]\n",
    "    print(str(len(data)) + ' after removing rows where pattern does not match') \n",
    "    data['days_since_upload'] = data.upload_date.apply(lambda x: days(x))\n",
    "    data = data[data['days_since_upload'] >0]\n",
    "    print(str(len(data)) + ' after removing rows where song is too new') \n",
    "    return data.drop('str_dv',axis=1)\n",
    "\n",
    "def add_popularity_measures(data):\n",
    "    data['days_views_ratio'] = data['views']/ data['days_since_upload']\n",
    "    data['days_views_ratio'] = np.where(data['days_views_ratio'] >= 10000, 10000, data['days_views_ratio'])\n",
    "    data['youtube_popularity'] = np.ceil(((data['days_views_ratio'] - (data['days_views_ratio'].min())) / \\\n",
    "                             (data['days_views_ratio'].max() - data['days_views_ratio'].min()))*100)\n",
    "    data['spotify_popularity'] = np.where(data['popularity'] == 0, 1, data['popularity'])\n",
    "    data['youtube_spotify_popularity_ratio'] = data['youtube_popularity']/ data['spotify_popularity']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csvs were split to small files with 100 rows each in order to perform the crawling. the first thing that we do is concat all of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = union_csvs(small_files_path).drop(labels = ['Unnamed: 0','Unnamed: 0.1'],axis =1 )\n",
    "raw_data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some coloumns need to be normalized between 0 to 1, and songs longer than 10 minutes are removed (mostly classical music or podcasts):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = normalize(raw_data)\n",
    "normalized.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "youtube upload dates and number of views are extrcted, and filtering is done for invalid values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = extract_dates_and_views(normalized)\n",
    "filtered.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "popularity measures are added according to the ratio of views and date since upload. the long tail is cut and the ration is normalized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_popularity = add_popularity_measures(filtered)\n",
    "with_popularity.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "redundant columns are removed and csv is exported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_popularity.artist_popularity = with_popularity.artist_popularity/100\n",
    "with_popularity.to_csv(\"random_songs_processed_dataset.csv\",encoding='utf-8',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
